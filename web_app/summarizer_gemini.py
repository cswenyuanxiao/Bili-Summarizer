
import os
from pathlib import Path
import sys
import time
from typing import Optional

import google.generativeai as genai
from dotenv import load_dotenv


def upload_to_gemini(file_path: Path, progress_callback=None):
    """
    ç‹¬ç«‹ä¸Šä¼ æ–‡ä»¶åˆ° Geminiï¼Œä¾›åç»­æ­¥éª¤å¤ç”¨ã€‚
    """
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("GOOGLE_API_KEY not found.")
    
    genai.configure(api_key=api_key)
    
    # MIME ç±»å‹æ˜ å°„
    mime_mapping = {
        '.mp4': 'video/mp4',
        '.mkv': 'video/x-matroska',
        '.webm': 'video/webm',
        '.mov': 'video/quicktime',
        '.avi': 'video/x-msvideo',
        '.mp3': 'audio/mpeg',
        '.m4a': 'audio/mp4',
        '.wav': 'audio/wav',
        '.aac': 'audio/aac',
        '.flac': 'audio/flac'
    }
    
    ext = file_path.suffix.lower()
    mime_type = mime_mapping.get(ext, 'application/octet-stream')
    
    print(f"æ­£åœ¨ä¸Šä¼ åª’ä½“æ–‡ä»¶: {file_path.name} (ç±»å‹: {mime_type})")
    if progress_callback:
        progress_callback(f"Uploading file to Google AI (Mime: {mime_type})...")
    
    try:
        media_file = genai.upload_file(path=str(file_path), mime_type=mime_type)
    except Exception as e:
        # å¦‚æœè¿˜æ˜¯æŠ¥é”™ï¼Œå°è¯•ä¸å¸¦ mime_type è®©å®ƒè‡ªé€‚åº”ï¼ˆè™½ç„¶é€šå¸¸è¿™å°±æ˜¯æŠ¥é”™åŸå› ï¼‰
        print(f"å¸¦MIMEä¸Šä¼ å¤±è´¥ï¼Œå°è¯•è‡ªåŠ¨æ¢æµ‹: {e}")
        media_file = genai.upload_file(path=str(file_path))
    
    # ç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæˆ
    while media_file.state.name == "PROCESSING":
        time.sleep(2)
        media_file = genai.get_file(media_file.name)
        if progress_callback:
             progress_callback(f"Cloud processing: {media_file.state.name}")
    
    if media_file.state.name == "FAILED":
        raise Exception("Google AI File Processing Failed")
        
    print(f"ä¸Šä¼ å®Œæˆ: {media_file.name}")
    return media_file

def delete_gemini_file(file_obj):
    """å®‰å…¨åˆ é™¤äº‘ç«¯æ–‡ä»¶"""
    try:
        if hasattr(file_obj, 'name'):
            genai.delete_file(file_obj.name)
            print(f"å·²æ¸…ç†äº‘ç«¯æ–‡ä»¶: {file_obj.name}")
    except Exception as e:
        print(f"æ¸…ç†äº‘ç«¯æ–‡ä»¶å¤±è´¥ (å¹¶ä¸å½±å“ç»“æœ): {e}")

# é…ç½®ä¸€ä¸ªæ¨¡å—çº§ Logger
import logging
logger = logging.getLogger("summarizer_gemini")


def extract_ai_transcript(file_path: Path, progress_callback=None, uploaded_file=None, retry_count=0) -> str:
    """
    ä½¿ç”¨ Gemini AI ä»è§†é¢‘/éŸ³é¢‘ä¸­æå–è¯­éŸ³è½¬å½•ã€‚
    æ”¯æŒä¼ å…¥å·²ä¸Šä¼ çš„ file å¯¹è±¡ (uploaded_file) ä»¥é¿å…é‡å¤ä¸Šä¼ ã€‚
    
    å†…ç½®é‡è¯•æœºåˆ¶ï¼Œæœ€å¤šé‡è¯• 2 æ¬¡ã€‚
    """
    MAX_RETRIES = 2
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        logger.error("GOOGLE_API_KEY not found, cannot extract transcript")
        return ""
    
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name="models/gemini-2.0-flash")
        
        # å¦‚æœ uploaded_file å­˜åœ¨ï¼Œè¯´æ˜æ˜¯å¹¶è¡Œæ¨¡å¼ï¼Œmain.py å·²ç»å‘é€äº†ç»Ÿä¸€çš„è¿›åº¦æ¶ˆæ¯
        if progress_callback and not uploaded_file:
            progress_callback("Extracting transcript with AI...")
        
        # 1. ç¡®å®šä½¿ç”¨çš„åª’ä½“æ–‡ä»¶å¯¹è±¡
        media_file = uploaded_file
        file_owned = False # æ ‡è®°æ˜¯å¦æ˜¯åœ¨æœ¬å‡½æ•°å†…ä¸Šä¼ çš„ï¼ˆå¦‚æœæ˜¯ï¼Œåˆ™è´Ÿè´£åˆ é™¤ï¼‰

        if not media_file:
            # ä½¿ç”¨ç»Ÿä¸€çš„ä¸Šä¼ é€»è¾‘ä»¥å¤„ç† MIME ç±»å‹
            media_file = upload_to_gemini(file_path, progress_callback)
            file_owned = True
        
        # 2. ä½¿ç”¨ä¸“é—¨çš„è½¬å½•æç¤ºè¯
        transcript_prompt = """è¯·ä»”ç»†å¬å–è¿™ä¸ªè§†é¢‘/éŸ³é¢‘ä¸­çš„æ‰€æœ‰è¯­éŸ³å†…å®¹ï¼Œå¹¶ç”Ÿæˆå®Œæ•´çš„è½¬å½•æ–‡æœ¬ã€‚

è¦æ±‚ï¼š
1. é€å¥è½¬å½•æ‰€æœ‰è¯­éŸ³å†…å®¹ï¼Œä¸è¦é—æ¼
2. æ¯ä¸€å¥è¯å‰éƒ½æ·»åŠ æ—¶é—´æˆ³ï¼Œæ—¶é—´æˆ³é—´éš”å°½é‡åœ¨ 2-5 ç§’å†…ï¼Œä¸è¦è·³ 30 ç§’ä»¥ä¸Š
3. æ—¶é—´æˆ³æ ¼å¼ç»Ÿä¸€ä¸º [mm:ss] æˆ– [hh:mm:ss]ï¼ˆä¸è¦æ¯«ç§’ï¼‰
4. ä¿æŒåŸå§‹è¯­è¨€ï¼ˆä¸­æ–‡å†…å®¹ç”¨ä¸­æ–‡ï¼Œè‹±æ–‡ç”¨è‹±æ–‡ï¼‰
5. å¦‚æœæœ‰å¤šä¸ªè¯´è¯è€…ï¼Œå°½é‡åŒºåˆ†æ ‡æ³¨
6. åªè¾“å‡ºè½¬å½•å†…å®¹ï¼Œä¸è¦æ·»åŠ æ€»ç»“æˆ–åˆ†æ

ç¤ºä¾‹æ ¼å¼ï¼š
[00:00] å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°ä»Šå¤©çš„è§†é¢‘...
[00:03] ä»Šå¤©æˆ‘ä»¬è¦è®¨è®ºçš„è¯é¢˜æ˜¯...
[00:07] é¦–å…ˆè®©æˆ‘ä»¬æ¥çœ‹ç¬¬ä¸€ä¸ªè§‚ç‚¹...
"""
        
        response = model.generate_content(
            [transcript_prompt, media_file],
            request_options={"timeout": 600}
        )
        
        # 3. æ¸…ç†ï¼ˆä»…æ¸…ç†è‡ªå·±ä¸Šä¼ çš„æ–‡ä»¶ï¼Œä¼ å…¥çš„æ–‡ä»¶ç”±è°ƒç”¨è€…è´Ÿè´£æ¸…ç†ï¼‰
        if file_owned:
            try:
                genai.delete_file(media_file.name)
            except:
                pass
        
        if response.parts:
            logger.info("AI Transcript generated successfully.")
            return response.text
        logger.warning("AI Transcript returned empty parts.")
        return ""
        
    except Exception as e:
        logger.error(f"AIè½¬å½•æå–å¤±è´¥ (å°è¯• {retry_count + 1}/{MAX_RETRIES + 1}): {e}")
        
        # é‡è¯•æœºåˆ¶
        if retry_count < MAX_RETRIES:
            logger.info(f"æ­£åœ¨é‡è¯•è½¬å½•... (ç¬¬ {retry_count + 2} æ¬¡)")
            if progress_callback:
                progress_callback(f"Transcript failed, retrying... ({retry_count + 2}/{MAX_RETRIES + 1})")
            time.sleep(2)  # ç­‰å¾…2ç§’å†é‡è¯•
            return extract_ai_transcript(file_path, progress_callback, uploaded_file, retry_count + 1)
        
        logger.error(f"AIè½¬å½•æœ€ç»ˆå¤±è´¥ï¼Œå·²é‡è¯• {MAX_RETRIES} æ¬¡: {e}")
        return ""


def summarize_content(file_path: Path, media_type: str, progress_callback=None, focus: str = "default", uploaded_file=None, custom_prompt: Optional[str] = None, output_language: str = "zh", enable_cot: bool = False) -> str:
    """
    ä½¿ç”¨ Google Gemini API æ€»ç»“å†…å®¹ã€‚
    æ”¯æŒä¼ å…¥ uploaded_file ä»¥é¿å…é‡å¤ä¸Šä¼ ã€‚
    æ”¯æŒä¼ å…¥ custom_prompt ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿ã€‚
    æ”¯æŒä¼ å…¥ output_language è®¾ç½®è¾“å‡ºè¯­è¨€ã€‚
    æ”¯æŒä¼ å…¥ enable_cot å¯ç”¨æ€ç»´é“¾å±•ç¤ºã€‚
    """
    # è¯­è¨€æ˜ å°„
    lang_map = {
        "zh": "ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰",
        "en": "English",
        "ja": "æ—¥æœ¬èª",
        "ko": "í•œêµ­ì–´",
        "es": "EspaÃ±ol",
        "fr": "FranÃ§ais"
    }
    
    target_language = lang_map.get(output_language, "ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰")
    # 1. åŠ è½½å’Œé…ç½® API å¯†é’¥
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("é”™è¯¯: GOOGLE_API_KEY æœªåœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ã€‚")
    
    try:
        genai.configure(api_key=api_key)
        # ä½¿ç”¨å®Œæ•´çš„æ¨¡å‹åç§°
        model = genai.GenerativeModel(model_name="models/gemini-2.0-flash")
    except Exception as e:
        raise Exception(f"Google AI SDK é…ç½®å¤±è´¥: {e}")

    # å¦‚æœæä¾›äº†è‡ªå®šä¹‰ Promptï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨
    if custom_prompt:
        prompt_text = (
            f"{custom_prompt}\n\n"
            "è¦æ±‚ï¼š\n"
            "1. å¦‚æœè§†é¢‘æœ‰è§†è§‰ç”»é¢ï¼Œè¯·ç»“åˆç”»é¢ä¿¡æ¯æä¾›æ›´ä¸°å¯Œçš„æè¿°ã€‚\n"
            "2. æœ€ç»ˆæ€»ç»“æœ«å°¾å¿…é¡»åŒ…å«ä¸€ä¸ªæ€ç»´å¯¼å›¾ï¼ˆé™¤éä½ çš„æ¨¡æ¿æ˜ç¡®è¦æ±‚ä¸è¦ï¼‰ã€‚è¯·ä½¿ç”¨æ ‡å‡† Markdown æ— åºåˆ—è¡¨ï¼Œä¸è¦ä½¿ç”¨ Mermaidã€‚\n"
            "3. æ€ç»´å¯¼å›¾è¯·ä»¥ã€æ€ç»´å¯¼å›¾ã€‘ä¸ºæ ‡é¢˜ï¼Œåç»­åªè¾“å‡ºæ— åºåˆ—è¡¨ï¼Œä¸è¦é¢å¤–è§£é‡Šã€‚\n"
            "4. ç¦æ­¢ä½¿ç”¨å®¢å¥—å¼€åœºï¼ˆå¦‚â€œå¥½çš„/å½“ç„¶/ä¸‹é¢æ˜¯/è¿™æ˜¯å¯¹è§†é¢‘çš„æ€»ç»“â€ï¼‰ã€‚\n"
            "5. å…ˆç»™ 2-3 å¥æ¦‚è¿°ï¼Œå†ç”¨å°æ ‡é¢˜ç»„ç»‡å†…å®¹ï¼ˆå¦‚â€œå…³é”®è¦ç‚¹/ç»“è®º/å»ºè®®â€ï¼‰ã€‚\n"
            "6. ç›´æ¥ä½¿ç”¨æ ‡å‡† Markdown æ ¼å¼ã€‚\n"
            f"7. **é‡è¦**ï¼šè¯·ç”¨ {target_language} è¾“å‡ºä»¥ä¸‹æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬æ€»ç»“ã€æ€ç»´å¯¼å›¾èŠ‚ç‚¹æ–‡æœ¬ï¼‰ã€‚"
        )
    else:
        # æ ¹æ®ä¸åŒçš„è§†è§’è°ƒæ•´ Prompt
        focus_prompts = {
            "default": "æ·±åº¦åˆ†æå¹¶æ€»ç»“è§†é¢‘çš„æ ¸å¿ƒå†…å®¹ã€å…³é”®ç‚¹å’Œç»“è®ºã€‚",
            "study": "ä»¥å­¦ä¹ è€…çš„è§†è§’ï¼Œè¯¦ç»†æ€»ç»“è§†é¢‘ä¸­çš„æ ¸å¿ƒçŸ¥è¯†ç‚¹ã€å­¦æœ¯æ¦‚å¿µæˆ–æŠ€æœ¯ç»†èŠ‚ã€‚",
            "gossip": "ä»¥è§‚ä¼—äº’åŠ¨çš„è§†è§’ï¼Œæå–è§†é¢‘ä¸­çš„æ§½ç‚¹ã€é‡‘å¥ã€æ¢—ä»¥åŠæœ€å…·å¨±ä¹æ€§çš„ç¬é—´ã€‚",
            "business": "ä»¥å•†ä¸šåˆ†æå¸ˆè§†è§’ï¼Œæ‹†è§£è§†é¢‘èƒŒåçš„å•†ä¸šæ¨¡å¼ã€å¸‚åœºæœºä¼šæˆ–è¥é”€é€»è¾‘ã€‚"
        }
        
        selected_focus_desc = focus_prompts.get(focus, focus_prompts["default"])

        # CoT Prompt (å¦‚æœå¯ç”¨)
        cot_instruction = ""
        if enable_cot:
            cot_instruction = (
                "\n\n## ğŸ§  è¯·å…ˆå±•ç¤ºä½ çš„åˆ†ææ€è·¯\n"
                "åœ¨ç»™å‡ºæ­£å¼æ€»ç»“ä¹‹å‰ï¼Œè¯·å…ˆæŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºä½ çš„æ€è€ƒè¿‡ç¨‹ï¼š\n\n"
                "[COT_START]\n"
                "æ­¥éª¤ 1: å†…å®¹è¯†åˆ«\n"
                "[æ€è€ƒ]: (è¯·åœ¨æ­¤æè¿°ä½ å¯¹è§†é¢‘ç±»å‹å’Œä¸»é¢˜çš„åˆ¤æ–­)\n\n"
                "æ­¥éª¤ 2: ç»“æ„åˆ†æ\n"
                "[æ€è€ƒ]: (è¯·åœ¨æ­¤æè¿°è§†é¢‘çš„é€»è¾‘ç»“æ„)\n\n"
                "æ­¥éª¤ 3: è¦ç‚¹æå–\n"
                "[æ€è€ƒ]: (è¯·åœ¨æ­¤åˆ—å‡ºæœ€é‡è¦çš„ä¿¡æ¯ç‚¹)\n\n"
                "æ­¥éª¤ 4: æ€»ç»“ç­–ç•¥\n"
                "[æ€è€ƒ]: (è¯·åœ¨æ­¤è¯´æ˜ä½ å°†é‡‡ç”¨ä»€ä¹ˆæ–¹å¼æ€»ç»“)\n"
                "[COT_END]\n\n"
                "---\n\n"
                "å®Œæˆä¸Šè¿°æ€è€ƒåï¼Œè¯·ç»™å‡ºæ­£å¼çš„è§†é¢‘æ€»ç»“ï¼š\n\n"
            )

        prompt_text = (
            f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘åˆ†æåŠ©æ‰‹ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹è§†è§’è¿›è¡Œæ€»ç»“ï¼šã€{selected_focus_desc}ã€‘\n\n"
            f"{cot_instruction}"
            "è¦æ±‚ï¼š\n"
            "1. å¦‚æœè§†é¢‘æœ‰è§†è§‰ç”»é¢ï¼Œè¯·ç»“åˆç”»é¢ä¿¡æ¯æä¾›æ›´ä¸°å¯Œçš„æè¿°ã€‚\n"
            "2. æ‘˜è¦éœ€è¦æ¸…æ™°ã€ç»“æ„åŒ–ä¸”å…¨é¢ã€‚\n"
            "3. ã€é‡è¦ã€‘å¿…é¡»åœ¨æ€»ç»“çš„æœ«å°¾æä¾›ä¸€ä¸ªæ€ç»´å¯¼å›¾ï¼Œè¯·ä½¿ç”¨æ ‡å‡† Markdown æ— åºåˆ—è¡¨ï¼Œä¸è¦ä½¿ç”¨ Mermaid æˆ–ç¼–å·åˆ—è¡¨ã€‚\n"
            "4. æ€ç»´å¯¼å›¾è¯·ä»¥ã€æ€ç»´å¯¼å›¾ã€‘ä¸ºæ ‡é¢˜ï¼Œåç»­åªè¾“å‡ºæ— åºåˆ—è¡¨ï¼Œä¸è¦é¢å¤–è§£é‡Šã€‚\n"
            "5. ç¦æ­¢ä½¿ç”¨å®¢å¥—å¼€åœºï¼ˆå¦‚â€œå¥½çš„/å½“ç„¶/ä¸‹é¢æ˜¯/è¿™æ˜¯å¯¹è§†é¢‘çš„æ€»ç»“â€ï¼‰ã€‚\n"
            "6. å…ˆç»™ 2-3 å¥æ¦‚è¿°ï¼Œå†ç”¨å°æ ‡é¢˜ç»„ç»‡å†…å®¹ï¼ˆå¦‚â€œå…³é”®è¦ç‚¹/ç»“è®º/å»ºè®®â€ï¼‰ã€‚\n"
            "7. æ— åºåˆ—è¡¨ç¤ºä¾‹ï¼š\n"
            "- æ ¸å¿ƒä¸»é¢˜\n"
            "  - åˆ†æ”¯1\n"
            "    - å­ç‚¹1\n"
            "    - å­ç‚¹2\n"
            "  - åˆ†æ”¯2\n"
            "8. ç›´æ¥ä½¿ç”¨æ ‡å‡† Markdown æ ¼å¼ã€‚ä¸¥ç¦ä½¿ç”¨ LaTeX æ ¼å¼ï¼Œè¡¨ç¤ºæ–¹å‘è¯·ç›´æ¥ä½¿ç”¨ 'â†’' æˆ– '->'ã€‚\n"
            f"9. **é‡è¦**ï¼šè¯·ç”¨ {target_language} è¾“å‡ºä»¥ä¸‹æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬æ€»ç»“ã€æ€ç»´å¯¼å›¾èŠ‚ç‚¹æ–‡æœ¬ï¼‰ã€‚\n"
            "10. **æ•°æ®å¯è§†åŒ–**ï¼ˆå¯é€‰ï¼‰ï¼šå¦‚æœè§†é¢‘åŒ…å«ç»Ÿè®¡æ•°æ®ã€å¯¹æ¯”æˆ–è¶‹åŠ¿ï¼Œè¯·åœ¨æ€ç»´å¯¼å›¾ä¹‹åè¾“å‡ºå›¾è¡¨ï¼š\n"
            "```json\n"
            '{"charts": [{"type": "bar", "title": "æ ‡é¢˜", "data": {"labels": ["A"], "values": [10]}}]}\n'
            "```\n"
            "typeå¯é€‰: bar/pie/lineã€‚"
        )

    content_parts = [prompt_text]
    file_to_delete = None # æœ¬åœ°ä¸Šä¼ çš„æ–‡ä»¶éœ€è¦åˆ é™¤
    
    try:
        # --- å­—å¹•æ¨¡å¼ (æ–‡æœ¬åˆ†æ) ---
        if media_type == 'subtitle':
            print(f"æ­£åœ¨å¤„ç†å­—å¹•æ–‡ä»¶: {file_path.name}")
            if progress_callback:
                progress_callback("Reading subtitle file...")
            
            try:
                try:
                    text_content = file_path.read_text(encoding='utf-8')
                except UnicodeDecodeError:
                    text_content = file_path.read_text(encoding='gbk')

                content_parts.append(f"ä»¥ä¸‹æ˜¯è§†é¢‘çš„å­—å¹•/æ–‡æœ¬å†…å®¹:\n{text_content}")
            except Exception as e:
                raise Exception(f"æ— æ³•è¯»å–å­—å¹•æ–‡ä»¶: {e}")
        
        # --- è§†é¢‘/éŸ³é¢‘æ¨¡å¼ (å¤šæ¨¡æ€åˆ†æ) ---
        elif media_type in ['audio', 'video']:
            
            # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ uploaded_file
            if uploaded_file:
                if progress_callback:
                    progress_callback(f"Using pre-uploaded file for analysis...")
                content_parts.append(uploaded_file)
                # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸è®¾ç½® file_to_deleteï¼Œå› ä¸ºè¿™æ˜¯å…±äº«æ–‡ä»¶ï¼Œç”±å¤–éƒ¨è°ƒç”¨è€…è´Ÿè´£åˆ é™¤
            else:
                # ä½¿ç”¨ç»Ÿä¸€çš„ä¸Šä¼ é€»è¾‘ä»¥å¤„ç† MIME ç±»å‹
                video_file = upload_to_gemini(file_path, progress_callback)
                file_to_delete = video_file # æ ‡è®°éœ€è¦åˆ é™¤
                content_parts.append(video_file)

        # 3. è°ƒç”¨æ¨¡å‹è¿›è¡Œæ€»ç»“
        # å¦‚æœ uploaded_file å­˜åœ¨ï¼Œè¯´æ˜æ˜¯å¹¶è¡Œæ¨¡å¼ï¼Œmain.py å·²ç»å‘é€äº†ç»Ÿä¸€çš„è¿›åº¦æ¶ˆæ¯ï¼Œè¿™é‡Œä¸å†é‡å¤å‘é€
        if progress_callback and not uploaded_file:
            progress_callback("AI is analyzing content...")
            
        logger.info(f"å¼€å§‹ AI åˆ†æ: Model={model.model_name}, EnableCoT={enable_cot}")
        if enable_cot:
            logger.info("CoT æŒ‡ä»¤å·²å¯ç”¨ï¼Œç­‰å¾…æ€è€ƒè¿‡ç¨‹...")
            
        # å¢åŠ è¶…æ—¶æ—¶é—´åˆ° 1200 ç§’
        response = model.generate_content(content_parts, request_options={"timeout": 1200})
        
        # æ‰“å°éƒ¨åˆ†å“åº”å†…å®¹ç”¨äºè°ƒè¯•
        logger.info(f"AI å“åº”å‰ 500 å­—ç¬¦: {response.text[:500]}")
        
        # åŒç†ï¼Œå®Œæˆæ¶ˆæ¯ä¹Ÿåªåœ¨éå¹¶è¡Œæ¨¡å¼ä¸‹å‘é€
        if progress_callback and not uploaded_file:
            progress_callback("Analysis complete! Formatting result...")
        
        # 4. æ¸…ç† (ä¸å†è‡ªåŠ¨æ¸…ç†ï¼Œç•™ç»™ main.py ç»Ÿä¸€ç®¡ç†æˆ–ä¾èµ– GC)
        # if file_to_delete:
        #    delete_gemini_file(file_to_delete)
        
        if not response.parts:
             raise Exception(f"AIæœªèƒ½ç”Ÿæˆæœ‰æ•ˆå›å¤")

        logger.info("AI Content Summary generated successfully.")
        # Extract usage metadata
        usage = {
            "prompt_tokens": response.usage_metadata.prompt_token_count,
            "completion_tokens": response.usage_metadata.candidates_token_count,
            "total_tokens": response.usage_metadata.total_token_count
        }

        # è§£æ CoT å†…å®¹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        response_text = response.text
        if enable_cot:
            logger.info(f"CoT è§£æ: [COT_START]={('[COT_START]' in response_text)}, [COT_END]={('[COT_END]' in response_text)}")
            
            if "[COT_START]" in response_text and "[COT_END]" in response_text:
                try:
                    cot_start = response_text.index("[COT_START]")
                    cot_end = response_text.index("[COT_END]") + len("[COT_END]")
                    cot_content = response_text[cot_start:cot_end]
                    
                    logger.info(f"CoT å‰200å­—ç¬¦: {cot_content[:200]}")
                    
                    import re
                    # æ›´å®½å®¹çš„æ­£åˆ™ï¼šå…¼å®¹ä¸­è‹±æ–‡å†’å·
                    steps = re.findall(
                        r'(?:###\s*)?æ­¥éª¤\s*(\d+)[:ï¼š]\s*(.+?)\n\s*\[æ€è€ƒ\][:ï¼š]\s*(.+?)(?=\n\n|\n(?:###\s*)?æ­¥éª¤|\[COT_END\]|$)',
                        cot_content, re.DOTALL
                    )
                    
                    logger.info(f"æ­£åˆ™åŒ¹é…åˆ° {len(steps)} ä¸ªæ­¥éª¤")
                    
                    if steps:
                        cot_steps = [{"step": int(num), "title": title.strip(), "thinking": thinking.strip()} for num, title, thinking in steps]
                        usage["cot_steps"] = cot_steps
                    else:
                        # å…œåº•ï¼šè¿”å›åŸå§‹æ–‡æœ¬
                        raw_cot = cot_content.replace("[COT_START]", "").replace("[COT_END]", "").strip()
                        usage["cot_steps"] = [{"step": 0, "title": "AI åˆ†æè¿‡ç¨‹", "thinking": raw_cot}]
                    
                    response_text = response_text[:cot_start] + response_text[cot_end:]
                    response_text = response_text.replace("---\n\n", "").strip()
                except Exception as e:
                    logger.warning(f"CoT è§£æå¤±è´¥: {e}")
            else:
                logger.warning("CoT å¯ç”¨ä½†æœªæ£€æµ‹åˆ°æ ‡è®°")

        # è§£æå›¾è¡¨æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if "```json" in response_text and "charts" in response_text:
            try:
                import json
                import re
                # æå– JSON ä»£ç å—
                json_match = re.search(r'```json\s*(\{.*?"charts".*?\})\s*```', response_text, re.DOTALL)
                if json_match:
                    chart_json = json_match.group(1)
                    chart_data = json.loads(chart_json)
                    if "charts" in chart_data and isinstance(chart_data["charts"], list):
                        usage["charts"] = chart_data["charts"]
                        # ç§»é™¤ JSON ä»£ç å—
                        response_text = response_text.replace(json_match.group(0), "").strip()
            except Exception as e:
                logger.warning(f"Failed to parse chart data: {e}")

        return response_text, usage

    except Exception as e:
        logger.error(f"AI æ€»ç»“æœ€ç»ˆå¤±è´¥: {e}")
        # Error Cleanup
        if file_to_delete:
            try:
                genai.delete_file(file_to_delete.name)
            except:
                pass
        raise Exception(f"AI æ€»ç»“å¤±è´¥: {e}")

import json

def generate_ppt_structure(summary_text: str) -> dict:
    """
    æ ¹æ®è§†é¢‘æ€»ç»“å†…å®¹ï¼Œç”Ÿæˆ PPT ç»“æ„çš„ JSON æ•°æ®ã€‚
    ä½¿ç”¨ Gemini æ¨¡å‹è¿›è¡Œè½¬æ¢ã€‚
    """
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("GOOGLE_API_KEY not found.")
    
    genai.configure(api_key=api_key)
    # ä½¿ç”¨è¾ƒå¿«çš„æ¨¡å‹å¤„ç†ç®€å•çš„æ ¼å¼è½¬æ¢ä»»åŠ¡
    model = genai.GenerativeModel("models/gemini-2.0-flash")
    
    prompt = """User wants to turn the following textual summary into a PowerPoint presentation.
    Please act as a Presentation Expert and structure the content into a JSON format suitable for generating slides.

    Output Rules:
    1. Language: Use the same language as the input summary (mostly Chinese).
    2. Slides count: 5 to 12 slides depending on content length.
    3. Content: Use concise bullet points.
    4. Format: STRICTLY JSON format. Do not obscure it with markdown code blocks if possible, or I will have to strip them.

    Target JSON Structure:
    {
        "title": "Presentation Title",
        "subtitle": "Subtitle or Author",
        "slides": [
            {
                "title": "Slide Title",
                "content": [
                    "Bullet point 1",
                    "Bullet point 2",
                    "Bullet point 3"
                ]
            }
        ]
    }

    --- INPUT SUMMARY START ---
    """ + summary_text + "\n--- INPUT SUMMARY END ---"

    try:
        response = model.generate_content(prompt)
        text = response.text.strip()
        
        # Clean Markdown Code Blocks
        if text.startswith("```json"):
            text = text[7:]
        elif text.startswith("```"):
            text = text[3:]
        
        if text.endswith("```"):
            text = text[:-3]
            
        return json.loads(text)
    except Exception as e:
        print(f"PPT Structure Generation Failed: {e}", file=sys.stderr)
        # Return a fallback structure
        return {
            "title": "è‡ªåŠ¨ç”Ÿæˆå¤±è´¥",
            "subtitle": "è¯·é‡è¯•æˆ–æ£€æŸ¥æ—¥å¿—",
            "slides": [
                {
                    "title": "Error",
                    "content": [str(e)]
                }
            ]
        }


if __name__ == '__main__':
    # ç”¨äºç›´æ¥æµ‹è¯• summarizer_gemini.py æ¨¡å—
    # è¿™ä¸ªæµ‹è¯•éœ€è¦ä¸€ä¸ªå·²ä¸‹è½½çš„è§†é¢‘æ–‡ä»¶
    try:
        # å‡è®¾è§†é¢‘ 'BV12b421v7xN.mp4' å·²ç»å­˜åœ¨äº videos æ–‡ä»¶å¤¹ä¸­
        PROJECT_ROOT = Path(__file__).resolve().parent.parent
        test_video_path = PROJECT_ROOT / "videos" / "BV12b421v7xN.mp4"

        if not test_video_path.exists():
            print("æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ downloader.py ä¸‹è½½è§†é¢‘ã€‚", file=sys.stderr)
            sys.exit(1)

        print("--- å¼€å§‹æµ‹è¯• AI æ€»ç»“æ¨¡å— ---")
        summary = summarize_content(test_video_path, 'video')
        print("\n--- è§†é¢‘æ‘˜è¦ ---")
        print(summary)
        print("\n--- æµ‹è¯•æˆåŠŸ! ---")

    except Exception as e:
        print(f"\n--- æµ‹è¯•å¤±è´¥ ---", file=sys.stderr)
        print(f"{e}", file=sys.stderr)
